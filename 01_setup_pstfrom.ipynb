{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d320466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy\n",
    "import pyemu\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import herebedragons as hbd\n",
    "import shutil\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ec79c",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "These notebooks will be less verbose than other GMDSI tutorial notebooks. We assume the reader is already familiar with many of the topics. We focus specificaly on aspects that relate to:\n",
    "- `PstFrom` with a `mf6` `disv` grid\n",
    "- use of hyper parameters\n",
    "- passing in prior knowledge to hyperparameters\n",
    "- (subsequent notebooks) use of DSI\n",
    "\n",
    "As usual, let's make a copy of our model folder for safety..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing original model files\n",
    "org_d = os.path.join('model')\n",
    "\n",
    "# a dir to hold a copy of the org model files\n",
    "tmp_d = os.path.join('tmp')\n",
    "\n",
    "if os.path.exists(tmp_d):\n",
    "    shutil.rmtree(tmp_d)\n",
    "shutil.copytree(org_d,tmp_d)\n",
    "\n",
    "# get executables\n",
    "hbd.get_bins(tmp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eef6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load simulation\n",
    "sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_d)\n",
    "# load flow model\n",
    "gwf = sim.get_model()\n",
    "\n",
    "# run the model once to make sure it works\n",
    "#pyemu.os_utils.run(\"mf6\",cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca97268",
   "metadata": {},
   "source": [
    "This model is a `DISV` grid. `PstFrom` is going to require the `flopy` model grid object to setup pilot points and spatialy varying covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = gwf.modelgrid\n",
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafdb4b",
   "metadata": {},
   "source": [
    "Apart from that, everything else is the same...magic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d203cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a template directory (i.e. the PstFrom working folder)\n",
    "template_ws = os.path.join(\"pst_template\")\n",
    "\n",
    "start_datetime = sim.tdis.start_date_time.get_data()\n",
    "\n",
    "# instantiate PstFrom\n",
    "pf = pyemu.utils.PstFrom(original_d=tmp_d,       # where the model is stored\n",
    "                            new_d=template_ws,   # the PEST template folder\n",
    "                            remove_existing=True, # ensures a clean start\n",
    "                            longnames=True,      # set False if using PEST/PEST_HP\n",
    "                            spatial_reference=sr, #the spatial reference we generated earlier\n",
    "                            zero_based=False, # does the MODEL use zero based indices? For example, MODFLOW does NOT\n",
    "                            start_datetime=start_datetime, # required when specifying temporal correlation between parameters\n",
    "                            echo=False) # to stop PstFrom from writing lots of information to the notebook; experiment by setting it as True to see the difference; useful for troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa6d8a",
   "metadata": {},
   "source": [
    "We are going to keep things super simple for this tutorial. We are only going to parameterize hydrualic conductivity. As we are all sofisticated, we understand that in a real-world application other parameters and boundary conditions would likely also be important aspects to consider for data assimilation and uncertianty analysis...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file that contains K values\n",
    "f = \"gwf.npf_k.txt\"\n",
    "\n",
    "# clean up the fname array file\n",
    "fpath = os.path.join(template_ws,f)\n",
    "\n",
    "k = np.loadtxt(fpath)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da02034",
   "metadata": {},
   "source": [
    "Unfortunatley `flopy` doesnt write tidy model input files...so we need to fix them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper function\n",
    "from herebedragons import tidy_array\n",
    "tidy_array(fpath)\n",
    "k = np.loadtxt(fpath)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76203cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = gwf.dis.idomain.get_data()\n",
    "assert ib is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666c6b4",
   "metadata": {},
   "source": [
    "No one specifgied the `idomain` in the original model setup, so lets just create a \"zone array\". `PstFrom` expects this when we setup pilot points and so on later. Note that the shape of `ib` is the same as the shape of the `k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66362b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = np.ones(sr.ncpl, dtype=int)\n",
    "assert ib.shape == k.shape\n",
    "ib.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92371058",
   "metadata": {},
   "source": [
    "Now, we have a set of pilot point locations (and values) already prepared from our conceptual modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd36ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf = pd.read_csv(os.path.join(\"data\",\"conceptual_kh.pts\"), sep=r'\\s+')\n",
    "ppdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b482b",
   "metadata": {},
   "source": [
    "However, `PstFrom` and `pypestutils` expect a strict format in terms of column anmes and information. So first we need to make that. A pilot point file must have the following columns: `['name','zone','x','y','parval1']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf = ppdf.astype(float)\n",
    "ppdf.rename(columns={'point':'name','easting':\"x\",\"northing\":\"y\",}, inplace=True)\n",
    "ppdf.name = ppdf.name.apply(lambda x: f'pp{int(x)}')\n",
    "ppdf['zone'] = 1\n",
    "ppdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cf75f",
   "metadata": {},
   "source": [
    "We have them all, except for `parval1`. We will be specifying that case by case below. lets start with the \"mean\" value of K pilot points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c98ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parval1 as the mean values of K\n",
    "ppdf['parval1'] = ppdf['mean']\n",
    "\n",
    "# take a look at the final pilot point file\n",
    "ppdf[['name','zone','x','y','parval1']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6384e",
   "metadata": {},
   "source": [
    "We spatialy varying mean values of K in the conceptaul pilot points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf.parval1.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72653749",
   "metadata": {},
   "source": [
    "But the value of K is uniform in the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b556f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gwf.npf.k.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d085a",
   "metadata": {},
   "source": [
    "Lets fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf.parval1 = ppdf.parval1 / np.unique(gwf.npf.k.get_data())[0]\n",
    "ppdf[['name','zone','x','y','parval1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save the file into the template folder\n",
    "ppfname = \"ppoints.k.csv\"\n",
    "ppdf[['name','zone','x','y','parval1']].to_csv(os.path.join(template_ws,ppfname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d530d9c",
   "metadata": {},
   "source": [
    "Now, setup a goestatistical structure to pass to `PstFrom`. This is the geostatiscs for the \"hyper parameter\". Inception much...\n",
    "\n",
    "Lets just use the median from the conceptual pilot points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ad313",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ppdf.describe().loc['50%','a'] # range of correlation; length units of the model. In our case 'meters'\n",
    "anisotropy = ppdf.describe().loc['50%','hanis'] #name says it all\n",
    "bearing = ppdf.describe().loc['50%','bearing'] #angle in degrees East of North corresponding to anisotropy ellipse\n",
    "a,anisotropy,bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential variogram for spatially varying parameters\n",
    "v_pp = pyemu.geostats.ExpVario(contribution=1.0, #sill\n",
    "                                    a=a, # range of correlation; length units of the model. In our case 'meters'\n",
    "                                    anisotropy=anisotropy, #name says it all\n",
    "                                    bearing=bearing #angle in degrees East of North corresponding to anisotropy ellipse\n",
    "                                    )\n",
    "\n",
    "# geostatistical structure for spatially varying parameters\n",
    "pp_gs = pyemu.geostats.GeoStruct(variograms=v_pp, transform='log') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53739a",
   "metadata": {},
   "source": [
    "Now we can set up pilot point multiplier parameters. \n",
    "\n",
    "Key aspects here are:\n",
    "\n",
    "```\n",
    "    initial_value=ppdf.parval1.values,\n",
    "```\n",
    "\n",
    "Where we have passed in the initial values for the K multipliers at each pilot point. And,\n",
    "\n",
    "```\n",
    "    pp_options={\"prep_hyperpars\":True, \"pp_space\":ppfname}\n",
    "```\n",
    "\n",
    "Where we have specfied that `PstFrom` shoudl setup hyper parameters, and use the `ppfname` file for pilot point locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fa97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ppdf['mean'].values       # means (linear)\n",
    "v10 = ppdf['var'].values       # variance of log10\n",
    "\n",
    "s10 = np.sqrt(v10)\n",
    "ln10 = np.log(10.0)\n",
    "sigma = s10 * ln10       # std dev in natural log\n",
    "z95 =  1.6448536269514722\n",
    "z05 = -z95\n",
    "\n",
    "lb = m * np.exp(-0.5 * sigma**2 + z05 * sigma)\n",
    "ub = m * np.exp(-0.5 * sigma**2 + z95 * sigma)\n",
    "\n",
    "# make to multiplier\n",
    "lb = lb / np.unique(gwf.npf.k.get_data())[0]\n",
    "ub = ub / np.unique(gwf.npf.k.get_data())[0]\n",
    "lb,ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf.parval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pilot point for \"mean\" hyperparamter\n",
    "df_pp = pf.add_parameters(f,\n",
    "                    zone_array=ib,\n",
    "                    par_type=\"pilotpoints\",\n",
    "                    geostruct=pp_gs,\n",
    "                    par_name_base=f.split('.')[1].replace(\"_\",\"\")+\"pp\",\n",
    "                    pargp=f.split('.')[1].replace(\"_\",\"\")+\"pp\",\n",
    "                    lower_bound=lb,\n",
    "                    upper_bound=ub,\n",
    "                    #ult_ubound=uubnd, ult_lbound=ulbnd,\n",
    "                    initial_value=ppdf.parval1.values,\n",
    "                    pp_options={\"prep_hyperpars\":True,\n",
    "                                \"pp_space\":ppfname}\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598145a",
   "metadata": {},
   "source": [
    "To make our lives easier and help with checking & postprocessing, lets add observations of K in every model cell. This will allow us to see the outcomes of the interpolation of the pilot point values to the grid..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6945a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pf.add_observations(f, prefix=\"k\", obsgp=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "mv = flopy.plot.PlotMapView(model=gwf)\n",
    "mv.plot_grid(lw=0.5,alpha=0.5)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.scatter(df_pp.x,df_pp.y, s=10,\n",
    "           c=df_pp.parval1,marker='o', zorder=3);\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2d848",
   "metadata": {},
   "source": [
    "Lets checkout what `pp_options={\"prep_hyperpars\":True}` did. It created a bunch of hyper parameter pilot point files for bearing, corrlength and anisotropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=\"npfkpp\"\n",
    "\n",
    "hyperpar_files = [f for f in os.listdir(pf.new_d) if tag in f]\n",
    "hyperpar_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a3d0b",
   "metadata": {},
   "source": [
    "OK, so lets go through each of the hyper parameters an dparameterize them using pilot points...same as before..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd86e6",
   "metadata": {},
   "source": [
    "Lets start with anisotropy. We are going to make these hyperparameters all \"additive\" type paraemters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont want to log transform anisotropy, so we should set up a geostatistical structure with 'none' transform\n",
    "# geostatistical structure for spatially varying parameters\n",
    "pp_gs_none = pyemu.geostats.GeoStruct(variograms=v_pp, transform='none') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppfname = \"ppoints.aniso.csv\"\n",
    "ppdf['parval1'] = ppdf['hanis']\n",
    "ppdf[['name','zone','x','y','parval1']].to_csv(os.path.join(template_ws,ppfname), index=False)\n",
    "ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ce04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08794faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e96c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afile = tag+'.aniso.dat'\n",
    "\n",
    "\n",
    "tidy_array(os.path.join(template_ws,afile))\n",
    "\n",
    "atag = afile.split('.')[0].replace(\"_\",\"-\")+\"-aniso\"\n",
    "_df = pf.add_parameters(afile,\n",
    "                  par_type=\"pilotpoints\",\n",
    "                  zone_array=ib.flatten(),\n",
    "                  geostruct=pp_gs_none,\n",
    "                  par_name_base=atag,\n",
    "                  pargp=atag,\n",
    "                  lower_bound=-2.5,upper_bound=2.5,\n",
    "                  ult_ubound=8., ult_lbound=0.,\n",
    "                  apply_order=1,\n",
    "                  par_style=\"a\",transform=\"none\",\n",
    "                  initial_value= ppdf['parval1'].values - anisotropy,\n",
    "                  pp_options={\"prep_hyperpars\":False,\n",
    "                              \"try_use_ppu\":True,\n",
    "                                \"pp_space\":ppfname})\n",
    "_ = pf.add_observations(afile, prefix=atag, obsgp=atag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567fbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03471fa7",
   "metadata": {},
   "source": [
    "Now bearing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21078d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppfname = \"ppoints.bearing.csv\"\n",
    "ppdf['parval1'] = ppdf['bearing']\n",
    "ppdf[['name','zone','x','y','parval1']].to_csv(os.path.join(template_ws,ppfname), index=False)\n",
    "ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile = tag+'.bearing.dat'\n",
    "tidy_array(os.path.join(template_ws,afile))\n",
    "atag = afile.split('.')[0].replace(\"_\",\"-\")+\"-bearing\"\n",
    "_df = pf.add_parameters(afile,\n",
    "                  par_type=\"pilotpoints\",\n",
    "                  zone_array=ib.flatten(),\n",
    "                  geostruct=pp_gs_none,\n",
    "                  par_name_base=atag,\n",
    "                  pargp=atag,\n",
    "                  lower_bound=-45,upper_bound=45,\n",
    "                  apply_order=1,\n",
    "                  par_style=\"a\",\n",
    "                  transform=\"none\",\n",
    "                  initial_value=ppdf['parval1'].values - bearing,\n",
    "                  pp_options={\"prep_hyperpars\":False,\n",
    "                              \"try_use_ppu\":True,\n",
    "                                \"pp_space\":ppfname})\n",
    "_ = pf.add_observations(afile, prefix=atag, obsgp=atag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25503bb9",
   "metadata": {},
   "source": [
    "Now correlation length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b56491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppfname = \"ppoints.corrlen.csv\"\n",
    "ppdf['parval1'] = ppdf['a']\n",
    "ppdf[['name','zone','x','y','parval1']].to_csv(os.path.join(template_ws,ppfname), index=False)\n",
    "ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "afile = tag+'.corrlen.dat'\n",
    "tidy_array(os.path.join(template_ws,afile))\n",
    "atag = afile.split('.')[0].replace(\"_\",\"-\")+\"-corrlen\"\n",
    "_df = pf.add_parameters(afile,\n",
    "                  par_type=\"pilotpoints\",\n",
    "                  zone_array=ib.flatten(),\n",
    "                  geostruct=pp_gs_none,\n",
    "                  par_name_base=atag,\n",
    "                  pargp=atag,\n",
    "                  lower_bound=0.5,upper_bound=2.0,\n",
    "                  ult_lbound=200, ult_ubound=1200,\n",
    "                  apply_order=1,\n",
    "                  par_style=\"m\",transform=\"none\",\n",
    "                  initial_value=ppdf['parval1'].values / a,\n",
    "                  pp_options={\"prep_hyperpars\":False,\n",
    "                              \"try_use_ppu\":True,\n",
    "                                \"pp_space\":ppfname})\n",
    "_ = pf.add_observations(afile, prefix=atag, obsgp=atag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc05dc",
   "metadata": {},
   "source": [
    "### Add postprocess functions\n",
    "To make sure that interpolated model input files are nice and tidy for `PEST` to read them as observations, lets add the `tidy_array()` function to the forward run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.extra_py_imports.append(\"numpy as np\")\n",
    "pf.add_py_function(\"herebedragons.py\",\"tidy_array('gwf.npf_k.txt')\",is_pre_cmd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5cbed",
   "metadata": {},
   "source": [
    "# Check the prior K fields\n",
    "\n",
    "An extremly useful check can be done now. Note that we have not yet added a model run to the `PstFrom`. All that is in the forward run workflow up to now is the interpolation from pilot points to the model grid. In other words, the interpolation is our \"forward run\" at the moment. \n",
    "\n",
    "Build the pest control file and forward run .py file to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da63b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pf.build_pst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(line.rstrip()) for line in open(os.path.join(template_ws,\"forward_run.py\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d561c",
   "metadata": {},
   "source": [
    "This is super powerful. We can generate a prior ensemble of pilot point values, run that ensemble and collate all the generater model input parameter fields. We can then check them and make sure they make sense and look pretty :) \n",
    "\n",
    "All we need to do is generate the ensemble and run it once. Because we are not running modflow, this will be super fast!\n",
    "\n",
    "Lets just make sure wverything is working first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c659cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(template_ws, 'pest.pst'),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run('pestpp-ies pest.pst', cwd=template_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d14e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(template_ws, 'pest.pst'))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329da731",
   "metadata": {},
   "source": [
    "Cool, so this is our base model run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a18cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=template_ws,load_only=['npf'],verbosity_level=0)\n",
    "gwf = sim.get_model()\n",
    "gwf.npf.k.plot(colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f5347",
   "metadata": {},
   "source": [
    "Generate the prior parameter ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the prior covariance matrix and store it as a compressed binary file (otherwise it can get huge!)\n",
    "# depending on your machine, this may take a while...\n",
    "if pf.pst.npar < 35000:  #if you have more than about 35K pars, the cov matrix becomes hard to handle\n",
    "    cov = pf.build_prior(fmt='coo', filename=os.path.join(template_ws,\"prior_cov.jcb\"))\n",
    "    # and take a peek at a slice of the matrix\n",
    "    try: \n",
    "        x = cov.x.copy()\n",
    "        x[x==0] = np.NaN\n",
    "        plt.imshow(x[:,:])\n",
    "    except:\n",
    "        pass\n",
    "    pf.pst.pestpp_options[\"parcov\"] = \"prior_cov.jcb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6936f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=1000, use_specsim=False) # draw parameters from the prior distribution\n",
    "pe.enforce() # enforces parameter bounds\n",
    "pe.to_binary(os.path.join(template_ws,\"prior_pe.jcb\")) #writes the parameter ensemble to binary file\n",
    "\n",
    "pst.pestpp_options[\"ies_par_en\"] = \"prior_pe.jcb\"\n",
    "pst.pestpp_options[\"ies_num_reals\"] = 50\n",
    "pst.write(os.path.join(template_ws,\"pest.pst\"),version=2)\n",
    "print(pe.shape,pf.pst.npar,pf.pst.npar_adj)\n",
    "assert pe.shape[1] == pf.pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb371cc2",
   "metadata": {},
   "source": [
    "Re-write the control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"overdue_giveup_fac\"] = 10\n",
    "pst.pestpp_options[\"overdue_giveup_minutes\"] = 100\n",
    "pst.pestpp_options[\"save_binary\"] = True\n",
    "\n",
    "pst.control_data.noptmax = -1\n",
    "\n",
    "pst.write(os.path.join(template_ws, 'pest.pst'),version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4b42b",
   "metadata": {},
   "source": [
    "And run `pestpp-ies`!\n",
    "\n",
    "### Warning: set number of workers to equal or less than the amount of cores you have available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee56f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_d = \"master_prior_cond\"\n",
    "t_d = template_ws\n",
    "\n",
    "pyemu.os_utils.start_workers(t_d, # the folder which contains the \"template\" PEST dataset\n",
    "                            'pestpp-ies', #the PEST software version we want to run\n",
    "                            'pest.pst', # the control file to use with PEST\n",
    "                            num_workers=num_workers, #how many agents to deploy\n",
    "                            worker_root='.', #where to deploy the agent directories; relative to where python is running\n",
    "                            master_dir=m_d, #the manager directory\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b24a1",
   "metadata": {},
   "source": [
    "Read in the results of the `pestpp-ies` prior monte carlo. We can use some the `Pst` inbuilt helpers for this. Start b reading the .pst file form the mater dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eed2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d, 'pest.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba450ff",
   "metadata": {},
   "source": [
    "Now, if parmeter or observation ensemble files are avialable in the folder, `pyemu` will try and load those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pst.ies.paren.copy()\n",
    "pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obsnmes = obs.loc[obs.oname==\"k\"].obsnme.tolist()\n",
    "\n",
    "onames = obs.oname.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247beac5",
   "metadata": {},
   "source": [
    "The same for the observation ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = pst.ies.obsen.copy()\n",
    "oe.loc[:,obsnmes].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0a371",
   "metadata": {},
   "source": [
    "Lets plot a couple of those parameter fields...good thing we tracked all the arrays as observations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07642411",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'base'#oe.index.values[1]\n",
    "for i in oe.index.values[-5:]:\n",
    "    fig,axs = plt.subplots(1,4,figsize=(16,4))\n",
    "\n",
    "    for e,oname in enumerate(onames):\n",
    "        ax = axs[e]\n",
    "        ax.set_aspect(\"equal\")\n",
    "        pm = flopy.plot.PlotMapView(model=gwf, ax=ax)\n",
    "\n",
    "        _obs = obs.loc[obs.oname==oname].copy()\n",
    "        _obs[\"i\"] = _obs[\"i\"].astype(int)\n",
    "        _obs.sort_values(\"i\", inplace=True)\n",
    "        obsnmes = _obs.obsnme.tolist()\n",
    "        arr = oe.loc[i,obsnmes].values\n",
    "        if oname=='k':\n",
    "            arr = np.log10(arr)\n",
    "\n",
    "        pa = pm.plot_array(arr)\n",
    "        plt.colorbar(pa, ax=ax, shrink=0.5)\n",
    "\n",
    "        ax.set_title(oname)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "\n",
    "    fig.tight_layout();\n",
    "    plt.show()\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24eb449",
   "metadata": {},
   "source": [
    "This provides a practical way of checking that all the plumibg works...that there arent silly mistakes with parameter values and bounds etc...and that you are happy with how the prior knowledge is being expressed through parameterisation. It can be quite helpfull to show results at this stage to stakeholders for example, to ensure that everyone agrees on the \"reasonableness\" of parameter values and distirbutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b23542",
   "metadata": {},
   "source": [
    "# Finishing up the PEST setup\n",
    "\n",
    "Once we are happy with that, we can go through the process of adding in the rest of the PEST setup. Such as observcations, other paramters...and importnatly the mf6 model run.\n",
    "\n",
    "To make our lives easier later on when we use DSI, we are simply going to track the model simualted heads and temperatures in all cells and all stressperiods. We have prepared a utulity function that processes `mf6` outpfiles and writes observations to clean .txt files (see `herebedragons.py` for details; its pretty simple). \n",
    "\n",
    "Lets just call it and run here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.post_model_outputs(template_ws=template_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd66a73",
   "metadata": {},
   "source": [
    "And add it to the `PstFrom`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.add_py_function(\"herebedragons.py\",\"post_model_outputs()\",is_pre_cmd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a78cdd",
   "metadata": {},
   "source": [
    "Now lets add observations from each of those files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile = \"riv.0.txt\"\n",
    "prefix ='riv'\n",
    "_ = pf.add_observations(afile, prefix=prefix, obsgp=prefix)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile = \"heads.0.txt\"\n",
    "prefix ='heads0'\n",
    "_ = pf.add_observations(afile, prefix=prefix, obsgp=prefix+'_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98760fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile = \"heads.1.txt\"\n",
    "prefix ='heads1'\n",
    "_ = pf.add_observations(afile, prefix=prefix, obsgp=prefix+\"_future\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "afile = \"temp.max.txt\"\n",
    "prefix ='temp_max'\n",
    "_ = pf.add_observations(afile, prefix=prefix, obsgp=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b131602",
   "metadata": {},
   "source": [
    "Eazy as...\n",
    "\n",
    "And last but not least, update the forward run script to call `mf6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.mod_sys_cmds.append(\"mf6\") #do this only once\n",
    "pf.mod_sys_cmds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02218ac4",
   "metadata": {},
   "source": [
    "Boom! good to go - lets build the pest setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2263ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pf.build_pst()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35e6c2",
   "metadata": {},
   "source": [
    "...just because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.weight = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeff0cf",
   "metadata": {},
   "source": [
    "Now we can draw the prior. Lets draw a large number of reals so we can play around with DSI later. \n",
    "\n",
    "And that is it...pest setup ready to run a prior monte carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=1000, use_specsim=False) # draw parameters from the prior distribution\n",
    "pe.enforce() # enforces parameter bounds\n",
    "\n",
    "\n",
    "pe.to_binary(os.path.join(template_ws,\"prior_pe.jcb\")) #writes the parameter ensemble to binary file\n",
    "\n",
    "\n",
    "pst.pestpp_options[\"ies_par_en\"] = \"prior_pe.jcb\"\n",
    "pst.pestpp_options[\"ies_num_reals\"] = 100\n",
    "pst.write(os.path.join(template_ws,\"pest.pst\"),version=2)\n",
    "print(pe.shape,pf.pst.npar,pf.pst.npar_adj)\n",
    "assert pe.shape[1] == pf.pst.npar_adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
